name: export-references
on:
  issues:
    types: [opened, edited, deleted]
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'

jobs:
  export:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Create env.js
        run: |
          echo "window.SUPABASE_URL = '${SUPABASE_URL}';" > docs/env.js
          echo "window.SUPABASE_ANON_KEY = '${SUPABASE_ANON_KEY}';" >> docs/env.js
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
      - name: Export reference issues to JSON
        id: export
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const issues = await github.paginate(github.rest.issues.listForRepo, {
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'reference',
              state: 'open',
              per_page: 100,
            });
              const map = {};
              for (const issue of issues) {
                const key = issue.title.toLowerCase();
                const existing = map[key];
                if (!existing || new Date(issue.updated_at) > new Date(existing.updated_at)) {
                  map[key] = issue;
                }
              }
              const deduped = Object.values(map);
              const data = deduped.map(i => ({
                id: i.number,
                number: i.number,
                title: i.title,
                user: i.user.login,
                url: i.html_url,
                created_at: i.created_at,
                body: i.body
              }));
            fs.mkdirSync('data', { recursive: true });
            fs.mkdirSync('docs/data', { recursive: true });
            const json = JSON.stringify(data, null, 2);
            fs.writeFileSync('data/literature.json', json);
            fs.writeFileSync('docs/data/literature.json', json);
      - name: Merge uploaded BibTeX
        run: |
          npm install bibtex-parse-js glob
          node <<'EOF'
          const fs = require('fs');
          const glob = require('glob');
          const parse = require('bibtex-parse-js');
          let data = [];
          try {
            data = JSON.parse(fs.readFileSync('data/literature.json', 'utf8'));
          } catch (e) {}
          let maxId = 0;
          data.forEach(item => { if (item.id && item.id > maxId) maxId = item.id; });
          const byTitle = new Map();
          const byDoi = new Map();
          const norm = s => (s || '').toLowerCase();
          const doiNorm = s => norm((s || '').replace(/https?:\/\/(dx\.)?doi.org\//, ''));
          data.forEach(item => {
            byTitle.set(norm(item.title), item);
            if (item.url) byDoi.set(doiNorm(item.url), item);
          });
          glob.sync('data/**/*.bib').forEach(file => {
            const content = fs.readFileSync(file, 'utf8');
            parse.toJSON(content).forEach(entry => {
              const f = entry.entryTags || {};
              const obj = {
                id: ++maxId,
                title: f.title || '',
                authors: f.author || '',
                year: f.year ? parseInt(f.year, 10) : undefined,
                journal: f.journal || f.booktitle || '',
                publisher: f.publisher || '',
                address: f.address || '',
                volume: f.volume || '',
                number: f.number || '',
                pages: f.pages || '',
                url: f.url || (f.doi ? `https://doi.org/${f.doi}` : ''),
                construct: '',
                axis: '',
                relevance: '',
                ratings: []
              };
              const tKey = norm(obj.title);
              const dKey = doiNorm(obj.url);
              if (byTitle.has(tKey) || (dKey && byDoi.has(dKey))) return;
              data.push(obj);
              byTitle.set(tKey, obj);
              if (dKey) byDoi.set(dKey, obj);
            });
          });
          fs.writeFileSync('data/literature.json', JSON.stringify(data, null, 2));
          fs.writeFileSync('docs/data/literature.json', JSON.stringify(data, null, 2));
          EOF
      - name: Commit updates
        uses: EndBug/add-and-commit@v9
        with:
          add: 'data/literature.json docs/data/literature.json'
          message: 'Update literature submissions'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - name: Upload to Supabase
        run: node scripts/upload_to_supabase.js data/literature.json literature
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
