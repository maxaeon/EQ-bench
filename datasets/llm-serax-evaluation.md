# ðŸ“Š LLM SERA-X Evaluation Rubric

This document outlines a 0â€“4 scoring rubric for rating large-language model (LLM) emotional intelligence on each SERA-X axis. The rubric is intended for human annotators evaluating model responses generated from prompts adhering to the [LLM SERA-X Dataset Schema](llm-serax-schema.md).

| Score | Description |
|-------|-------------|
| **0 â€“ Missing** | The response fails to address the axis or displays clear misunderstanding. |
| **1 â€“ Limited** | Minimal attempt at the axis skill; errors or omissions dominate. |
| **2 â€“ Adequate** | Reasonable demonstration of the axis skill with noticeable flaws. |
| **3 â€“ Strong** | Skillfully addresses the axis with minor issues or partial depth. |
| **4 â€“ Exceptional** | Thorough, coherent mastery of the axis with no major deficiencies. |

Each SERA-X axisâ€”**Sense**, **Explain**, **Respond**, **Adapt**, and **Extended**â€”is scored independently using this scale. A single model may exhibit different competency levels across axes. The rubric helps highlight strengths and opportunities for improvement.
