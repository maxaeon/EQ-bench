<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EQ AI Research Hub - Phase 3</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" href="assets/images/favicon.png">
</head>
<body>
    <a class="skip-link" href="#main">Skip to main content</a>
    <header>
        <h1><a class="logo" href="index.html">EQ AI Research Hub</a></h1>
        <button class="nav-toggle" aria-label="Toggle navigation">&#9776;</button>
        <nav class="site-nav" aria-label="Primary">
            <ul>
                <li class="dropdown">
                    <a href="research.html">Our Research Project</a>
                    <ul>
                        <li><a href="phase1.html">Phase 1</a></li>
                        <li><a href="phase2.html">Phase 2</a></li>
                        <li><a href="phase3.html">Phase 3</a></li>
                        <li><a href="phase4.html">Phase 4</a></li>
                    </ul>
                </li>
                <li><a href="expert-collaborators.html">Our Team of Experts</a></li>
                <li><a href="https://github.com/maxaeon/EQ-bench">GitHub Repository</a></li>
            </ul>
        </nav>

    </header>

    <main id="main">
        <section>
            <h1>Phase 3: Development of Benchmarking Methodology</h1>
            <div class="subsection">
                <h3>Goal</h3>
                <p>Establish standardized assessment methods for emotional intelligence.</p>
            </div>
            <div class="subsection">
                <h3>Methodology</h3>
                <ul>
                    <li>Standardized protocols for each SERA-X axis (Sensing, Explaining, Responding, Adapting, Extended)</li>
                    <li>Comprehensive evaluation rubric development</li>
                </ul>
            </div>
            <!-- SERA-X Database Connection Visualization -->
            <div>
<h2>Tentative Database Structure: Constructs, Literature, Evaluation Methods, and SERA-X Validation</h2>

<table style="width:100%; border-collapse:collapse; border:1px solid #ccc;">
  <thead>
    <tr>
      <th style="border:1px solid #ccc; padding:10px;">Construct</th>
      <th style="border:1px solid #ccc; padding:10px;">Linked Axes (SERA-X)</th>
      <th style="border:1px solid #ccc; padding:10px;">Supporting Literature</th>
      <th style="border:1px solid #ccc; padding:10px;">Evaluation Methods (AI systems)</th>
      <th style="border:1px solid #ccc; padding:10px;">Validated Benchmarks (Examples)</th>
    </tr>
  </thead>
  <tbody>
    <!-- Construct Example 1 -->
    <tr>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        Emotion Regulation
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        Responding, Adapting
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        <ul style="margin:0; padding-left:20px;">
          <li>Gross (1998)</li>
          <li>Picard (1997)</li>
        </ul>
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        <ul style="margin:0; padding-left:20px;">
          <li><strong>Human-annotated response quality:</strong> Experts rate AI-generated emotional responses for appropriateness.</li>
          <li><strong>Dynamic contextual adaptability:</strong> Multi-turn dialogue tests evaluating shifts in AI's emotional output based on context changes.</li>
        </ul>
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        GPT-4, Claude (LLM Dialogue Scores)
      </td>
    </tr>

    <!-- Construct Example 2 -->
    <tr>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        Emotion Recognition
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        Sensing
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        Picard (1997)
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        <ul style="margin:0; padding-left:20px;">
          <li><strong>Classification accuracy:</strong> Evaluating AI emotion detection accuracy on standardized emotion datasets (e.g., GoEmotions).</li>
          <li><strong>Precision and recall metrics:</strong> Statistical analysis of AI’s ability to correctly identify nuanced emotional expressions.</li>
        </ul>
      </td>
      <td style="border:1px solid #ccc; padding:10px; vertical-align:top;">
        Empathy Dataset (GoEmotions)
      </td>
    </tr>
  </tbody>
</table>

<h3>Conceptual Visualization of Data Relationships (Updated)</h3>
<pre style="padding:15px; border-radius:6px;">
Constructs
├── Emotion Regulation
│   ├── Axes: Responding, Adapting
│   ├── Literature:
│   │   ├── Gross (1998)
│   │   └── Picard (1997)
│   ├── Evaluation Methods:
│   │   ├── Human-annotated response quality
│   │   └── Dynamic contextual adaptability (multi-turn dialogue tests)
│   └── Benchmarks:
│       └── GPT-4, Claude (LLM scores)
│
├── Emotion Recognition
│   ├── Axes: Sensing
│   ├── Literature:
│   │   └── Picard (1997)
│   ├── Evaluation Methods:
│   │   ├── Classification accuracy (standardized datasets)
│   │   └── Precision and recall metrics
│   └── Benchmarks:
│       └── Empathy Dataset (GoEmotions)
│
Literature
├── Gross (1998)
│   └── Constructs: Emotion Regulation
│
└── Picard (1997)
    ├── Constructs: Emotion Recognition, Emotion Regulation
    └── Axes: Sensing, Responding, Adapting
</pre>

---

                <!-- Explanation of Validation -->
                <h3>SERA-X Validation Methodology (Tentative)</h3>
                <p>
                    Each construct is explicitly validated through literature evidence and empirical benchmark evaluations aligned with specific SERA-X axes:
                </p>
                <ul>
                    <li><strong>Sensing:</strong> Evaluations of AI's accuracy in identifying human emotional states.</li>
                    <li><strong>Explaining:</strong> Assessments of AI’s clarity and accuracy in justifying its emotional reasoning.</li>
                    <li><strong>Responding:</strong> Benchmarking AI’s effectiveness and appropriateness in responding emotionally to humans.</li>
                    <li><strong>Adapting:</strong> Measurement of AI's dynamic adaptation to changes in emotional context and user feedback.</li>
                    <li><strong>Extended:</strong> Evaluations of AI’s emotional intelligence in collaborative or distributed interactions.</li>
                </ul>
                <p>
                    Constructs are continuously refined through community submissions and rigorous validation processes, including expert literature reviews and empirical benchmarks utilizing standardized datasets (e.g., EmpatheticDialogues, GoEmotions).
                </p>
            </div>
        </section>
    </main>

    <footer>
        <p>&copy; EQ AI Research Collaborative</p>
    </footer>
    <script src="script.js"></script>
</body>
</html>
